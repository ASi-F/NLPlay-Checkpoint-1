{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN with tf-idf vectorization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwa8NiOYVdernvCsdb8a16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASi-F/NLPlay-Checkpoint-1/blob/main/FFNN_with_tf_idf_vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKtAgF5vjIGN",
        "outputId": "728643bd-9b46-4115-c1e4-ddc04f4c0e91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P7ZUND_jmpI"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IJpwOwxjtyE"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IMDB Dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "ildehDA2jxEJ",
        "outputId": "c6ed138b-79c4-4e0a-b2c9-af4f9514db8b"
      },
      "source": [
        "print(df.columns)\n",
        "df.describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['review', 'sentiment'], dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>49582</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   review sentiment\n",
              "count                                               50000     50000\n",
              "unique                                              49582         2\n",
              "top     Loved today's show!!! It was a variety and not...  positive\n",
              "freq                                                    5     25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoWTJcIvj0UG",
        "outputId": "e6127c09-9359-4b2b-a636-409a636eddea"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klY3OSO7j5MK"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "df['without_stopwords'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "yJzFzFpEj70r",
        "outputId": "5ba4b5df-0a68-43ce-dfb4-f4de5a1c08da"
      },
      "source": [
        "df['without_stopwords'][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One reviewers mentioned watching 1 Oz episode hooked. They right, exactly happened me.<br /><br />The first thing struck Oz brutality unflinching scenes violence, set right word GO. Trust me, show faint hearted timid. This show pulls punches regards drugs, sex violence. Its hardcore, classic use word.<br /><br />It called OZ nickname given Oswald Maximum Security State Penitentary. It focuses mainly Emerald City, experimental section prison cells glass fronts face inwards, privacy high agenda. Em City home many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish more....so scuffles, death stares, dodgy dealings shady agreements never far away.<br /><br />I would say main appeal show due fact goes shows dare. Forget pretty pictures painted mainstream audiences, forget charm, forget romance...OZ mess around. The first episode I ever saw struck nasty surreal, I say I ready it, I watched more, I developed taste Oz, got accustomed high levels graphic violence. Not violence, injustice (crooked guards who'll sold nickel, inmates who'll kill order get away it, well mannered, middle class inmates turned prison bitches due lack street skills prison experience) Watching Oz, may become comfortable uncomfortable viewing....thats get touch darker side.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ZBEftij_iV"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\", '\"', ','))\n",
        "    return final\n",
        "\n",
        "df['without_stopwords'] = df['without_stopwords'].apply(remove_punctuation)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9NPd5TQkCeL"
      },
      "source": [
        "def remove_tags(text):\n",
        "    final = \"\"\n",
        "    stt = True\n",
        "    for char in text:\n",
        "        if char == '<':\n",
        "            stt = False\n",
        "        if(stt):\n",
        "            final = final + char\n",
        "        if char == '>':\n",
        "            stt = True\n",
        "            final = final + ' '\n",
        "    return final\n",
        "df['without_stopwords'] = df['without_stopwords'].apply(remove_tags)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "MXFCJZ0PkH8R",
        "outputId": "7c008e3d-8434-49f2-b4b2-39610b72ce15"
      },
      "source": [
        "df['without_stopwords'][0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One reviewers mentioned watching 1 Oz episode hooked They right exactly happened me  The first thing struck Oz brutality unflinching scenes violence set right word GO Trust me show faint hearted timid This show pulls punches regards drugs sex violence Its hardcore classic use word  It called OZ nickname given Oswald Maximum Security State Penitentary It focuses mainly Emerald City experimental section prison cells glass fronts face inwards privacy high agenda Em City home manyAryans Muslims gangstas Latinos Christians Italians Irish moreso scuffles death stares dodgy dealings shady agreements never far away  I would say main appeal show due fact goes shows dare Forget pretty pictures painted mainstream audiences forget charm forget romanceOZ mess around The first episode I ever saw struck nasty surreal I say I ready it I watched more I developed taste Oz got accustomed high levels graphic violence Not violence injustice (crooked guards who'll sold nickel inmates who'll kill order get away it well mannered middle class inmates turned prison bitches due lack street skills prison experience) Watching Oz may become comfortable uncomfortable viewingthats get touch darker side\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "X7YBu6pAkPZA",
        "outputId": "9f7361e6-0f69-41d6-d81d-75808442c431"
      },
      "source": [
        "df['review'][0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUEYcmPlkT9F",
        "outputId": "768bb38e-0aef-4cfb-86ff-784e801937c8"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AunJ5Ymkat3"
      },
      "source": [
        "df['tokens'] = df['without_stopwords'].apply(nltk.word_tokenize)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF7onwKvkfge"
      },
      "source": [
        "def stem_tokens(tokens):\n",
        "    final = [nltk.stem.PorterStemmer().stem(word) for word in tokens]\n",
        "    return final\n",
        "    \n",
        "df['stemmed_tokens'] = df['tokens'].apply(stem_tokens)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFGahLankilD"
      },
      "source": [
        "df['label'] = [2*(sent=='positive')-1 for sent in df['sentiment']]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "pDh3S1AHkjN6",
        "outputId": "e9c15e36-e308-4475-a04a-3b4dc6ce4c9d"
      },
      "source": [
        "df.head(9)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>without_stopwords</th>\n",
              "      <th>tokens</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
              "      <td>[One, reviewers, mentioned, watching, 1, Oz, e...</td>\n",
              "      <td>[one, review, mention, watch, 1, Oz, episod, h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>A wonderful little production   The filming te...</td>\n",
              "      <td>[A, wonderful, little, production, The, filmin...</td>\n",
              "      <td>[A, wonder, littl, product, the, film, techniq...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>I thought wonderful way spend time hot summer ...</td>\n",
              "      <td>[I, thought, wonderful, way, spend, time, hot,...</td>\n",
              "      <td>[I, thought, wonder, way, spend, time, hot, su...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Basically there's family little boy (Jake) thi...</td>\n",
              "      <td>[Basically, there, 's, family, little, boy, (,...</td>\n",
              "      <td>[basic, there, 's, famili, littl, boy, (, jake...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Petter Mattei's Love Time Money visually stunn...</td>\n",
              "      <td>[Petter, Mattei, 's, Love, Time, Money, visual...</td>\n",
              "      <td>[petter, mattei, 's, love, time, money, visual...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Probably all-time favorite movie story selfles...</td>\n",
              "      <td>[Probably, all-time, favorite, movie, story, s...</td>\n",
              "      <td>[probabl, all-tim, favorit, movi, stori, selfl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "      <td>I sure would like see resurrection dated Seahu...</td>\n",
              "      <td>[I, sure, would, like, see, resurrection, date...</td>\n",
              "      <td>[I, sure, would, like, see, resurrect, date, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "      <td>This show amazing fresh &amp; innovative idea 70's...</td>\n",
              "      <td>[This, show, amazing, fresh, &amp;, innovative, id...</td>\n",
              "      <td>[thi, show, amaz, fresh, &amp;, innov, idea, 70, '...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Encouraged positive comments film I looking fo...</td>\n",
              "      <td>[Encouraged, positive, comments, film, I, look...</td>\n",
              "      <td>[encourag, posit, comment, film, I, look, forw...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ... label\n",
              "0  One of the other reviewers has mentioned that ...  ...     1\n",
              "1  A wonderful little production. <br /><br />The...  ...     1\n",
              "2  I thought this was a wonderful way to spend ti...  ...     1\n",
              "3  Basically there's a family where a little boy ...  ...    -1\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...     1\n",
              "5  Probably my all-time favorite movie, a story o...  ...     1\n",
              "6  I sure would like to see a resurrection of a u...  ...     1\n",
              "7  This show was an amazing, fresh & innovative i...  ...    -1\n",
              "8  Encouraged by the positive comments about this...  ...    -1\n",
              "\n",
              "[9 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD3UF41Ckl7S"
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "review_dict = corpora.Dictionary(df['stemmed_tokens'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkmJnE0_kywI",
        "outputId": "ac3208eb-4b23-40fe-d195-87d8c1e26f7e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Train Test Split Function\n",
        "\n",
        "def split_train_test(top_data_df_small, test_size=0.3, shuffle_state=True):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(top_data_df_small[['review','sentiment','without_stopwords','tokens','stemmed_tokens','label']], \n",
        "                                                        top_data_df_small['label'], \n",
        "                                                        shuffle=shuffle_state,\n",
        "                                                        test_size=test_size, \n",
        "                                                        random_state=15)\n",
        "    print(\"Value counts for Train sentiments\")\n",
        "    print(Y_train.value_counts())\n",
        "    print(\"Value counts for Test sentiments\")\n",
        "    print(Y_test.value_counts())\n",
        "    print(type(X_train))\n",
        "    print(type(Y_train))\n",
        "    X_train = X_train.reset_index()\n",
        "    X_test = X_test.reset_index()\n",
        "    Y_train = Y_train.to_frame()\n",
        "    Y_train = Y_train.reset_index()\n",
        "    Y_test = Y_test.to_frame()\n",
        "    Y_test = Y_test.reset_index()\n",
        "    print(X_train.head())\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "# Call the train_test_split\n",
        "X_train, X_test, Y_train, Y_test = split_train_test(df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value counts for Train sentiments\n",
            "-1    17512\n",
            " 1    17488\n",
            "Name: label, dtype: int64\n",
            "Value counts for Test sentiments\n",
            " 1    7512\n",
            "-1    7488\n",
            "Name: label, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "   index  ... label\n",
            "0  36322  ...     1\n",
            "1   4638  ...     1\n",
            "2  46808  ...    -1\n",
            "3  38099  ...    -1\n",
            "4  31461  ...     1\n",
            "\n",
            "[5 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "rXRkJFC6kzaq",
        "outputId": "b51e46ad-0fc7-485f-dc98-eb0e2f2f33fd"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>without_stopwords</th>\n",
              "      <th>tokens</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36322</td>\n",
              "      <td>The sequel is exactly what you will expect it ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>The sequel exactly expect be And good enough e...</td>\n",
              "      <td>[The, sequel, exactly, expect, be, And, good, ...</td>\n",
              "      <td>[the, sequel, exactli, expect, be, and, good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4638</td>\n",
              "      <td>This is a pretty well known one so i won't get...</td>\n",
              "      <td>positive</td>\n",
              "      <td>This pretty well known one get deep it The bas...</td>\n",
              "      <td>[This, pretty, well, known, one, get, deep, it...</td>\n",
              "      <td>[thi, pretti, well, known, one, get, deep, it,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46808</td>\n",
              "      <td>I made the mistake of buying this since I coll...</td>\n",
              "      <td>negative</td>\n",
              "      <td>I made mistake buying since I collect comic bo...</td>\n",
              "      <td>[I, made, mistake, buying, since, I, collect, ...</td>\n",
              "      <td>[I, made, mistak, buy, sinc, I, collect, comic...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38099</td>\n",
              "      <td>This movie is the proverbial 80s flick that sh...</td>\n",
              "      <td>negative</td>\n",
              "      <td>This movie proverbial 80s flick shows viewer l...</td>\n",
              "      <td>[This, movie, proverbial, 80s, flick, shows, v...</td>\n",
              "      <td>[thi, movi, proverbi, 80, flick, show, viewer,...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31461</td>\n",
              "      <td>I absolutely LOVED this movie as a child. I ca...</td>\n",
              "      <td>positive</td>\n",
              "      <td>I absolutely LOVED movie child I can't seem fi...</td>\n",
              "      <td>[I, absolutely, LOVED, movie, child, I, ca, n'...</td>\n",
              "      <td>[I, absolut, love, movi, child, I, ca, n't, se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34995</th>\n",
              "      <td>39296</td>\n",
              "      <td>When i started watching \"Surface\"for the first...</td>\n",
              "      <td>positive</td>\n",
              "      <td>When started watching Surfacefor first time ho...</td>\n",
              "      <td>[When, started, watching, Surfacefor, first, t...</td>\n",
              "      <td>[when, start, watch, surfacefor, first, time, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34996</th>\n",
              "      <td>49015</td>\n",
              "      <td>Are you kidding me? This is quite possibly the...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Are kidding me This quite possibly worst amate...</td>\n",
              "      <td>[Are, kidding, me, This, quite, possibly, wors...</td>\n",
              "      <td>[are, kid, me, thi, quit, possibl, worst, amat...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34997</th>\n",
              "      <td>2693</td>\n",
              "      <td>One would make you believe that this game is a...</td>\n",
              "      <td>negative</td>\n",
              "      <td>One would make believe game man obsessed numbe...</td>\n",
              "      <td>[One, would, make, believe, game, man, obsesse...</td>\n",
              "      <td>[one, would, make, believ, game, man, obsess, ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34998</th>\n",
              "      <td>8076</td>\n",
              "      <td>I'D BUY THAT FOR A DOLLAR!!!&lt;br /&gt;&lt;br /&gt;I did ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>I'D BUY THAT FOR A DOLLAR  I buy film dollar I...</td>\n",
              "      <td>[I, 'D, BUY, THAT, FOR, A, DOLLAR, I, buy, fil...</td>\n",
              "      <td>[I, 'D, buy, that, for, A, dollar, I, buy, fil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34999</th>\n",
              "      <td>7624</td>\n",
              "      <td>Seems to have been made as a vehicle for W.C. ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Seems made vehicle WC Fields Carol Dempster do...</td>\n",
              "      <td>[Seems, made, vehicle, WC, Fields, Carol, Demp...</td>\n",
              "      <td>[seem, made, vehicl, WC, field, carol, dempste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35000 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... label\n",
              "0      36322  ...     1\n",
              "1       4638  ...     1\n",
              "2      46808  ...    -1\n",
              "3      38099  ...    -1\n",
              "4      31461  ...     1\n",
              "...      ...  ...   ...\n",
              "34995  39296  ...     1\n",
              "34996  49015  ...    -1\n",
              "34997   2693  ...    -1\n",
              "34998   8076  ...     1\n",
              "34999   7624  ...     1\n",
              "\n",
              "[35000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2xbOxpqk2HP",
        "outputId": "048058e9-7330-4c7c-c85b-8f9fe6a90572"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-oOmoSBnKpF"
      },
      "source": [
        "# define FeedforwardNeuralNetwork\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size):\n",
        "        super(FeedForwardNN,self).__init__()\n",
        "        \n",
        "        # Linear fnction 1\n",
        "        self.LF1 = nn.Linear(input_size,hidden_size)\n",
        "        # Nonlinear fnction 1\n",
        "        self.NLF1 = nn.ReLU()\n",
        "        \n",
        "        # Linear function 2\n",
        "        self.LF2 = nn.Linear(hidden_size,hidden_size)\n",
        "        # Nonlinear fnction 2\n",
        "        self.NLF2 = nn.ReLU()\n",
        "        \n",
        "        #Linear function 2\n",
        "        self.LF3 = nn.Linear(hidden_size,output_size)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # Layer 1\n",
        "        out = self.LF1(x)\n",
        "        out = self.NLF1(out)\n",
        "        \n",
        "        #Layer 2 \n",
        "        out = self.LF2(out)\n",
        "        out = self.NLF2(out)\n",
        "        \n",
        "        #Layer 3\n",
        "        out = self.LF3(out)\n",
        "        \n",
        "        return F.softmax(out,dim=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAKEmr8xlPjJ"
      },
      "source": [
        "VOCAB_SIZE = len(review_dict)\n",
        "NUM_LABELS = 2\n",
        "import math\n",
        "def idf(word):\n",
        "  freq = 0\n",
        "  for tokens in df['stemmed_tokens']:\n",
        "    for token in tokens:\n",
        "      if token == word:\n",
        "        freq+=1\n",
        "        break\n",
        "  return math.log(len(df)/freq)\n",
        "\n",
        "def tf_idf_vector(review_dict, sentence):\n",
        "  vec = torch.zeros(VOCAB_SIZE, dtype = torch.float64, device = device)\n",
        "  for i in range(0,len(vec)):\n",
        "    vec[i]=-1\n",
        "  for word in sentence:\n",
        "    if vec[review_dict.token2id[word]] == -1:\n",
        "      freq = 0\n",
        "      for temp in sentence:\n",
        "       if temp == word:\n",
        "         freq+=1\n",
        "      tf = freq/len(sentence)\n",
        "      vec[review_dict.token2id[word]]= tf*idf(word)\n",
        "  for i in range(0,len(vec)):\n",
        "    if vec[i]==-1:\n",
        "      vec[i]=0\n",
        "\n",
        "  return vec.reshape(1,-1).float()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PUBadLnk87l"
      },
      "source": [
        "def make_pred(label):\n",
        "    if label == -1:\n",
        "        return torch.tensor([0], dtype = torch.long, device = device)\n",
        "    elif label == 1:\n",
        "        return torch.tensor([1], dtype = torch.long, device = device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLszbF8nlBeH"
      },
      "source": [
        "def train(num_epochs,batch_size,optimizer,loss_function = nn.CrossEntropyLoss()):\n",
        "  losses = []\n",
        "  task_len = num_epochs *len(X_train)\n",
        "  ittr = 0\n",
        "  for epoch in range(num_epochs):\n",
        "      train_loss = torch.tensor([0.],device = device)\n",
        "      for index,row in X_train.iterrows():\n",
        "          ittr+=1\n",
        "          if ittr%(task_len//100) == 0:\n",
        "            print(ittr*100//(task_len),'% complemeted')\n",
        "          # make bag of word vector \n",
        "          tf_idf_vec = tf_idf_vector(review_dict,row['stemmed_tokens'])\n",
        "        \n",
        "          # Forward pass\n",
        "          preds = FFNN(tf_idf_vec)\n",
        "        \n",
        "          # get target label\n",
        "          target = make_pred(Y_train['label'][index])\n",
        "\n",
        "          loss = loss_function(preds, target)\n",
        "  \n",
        "          train_loss +=loss\n",
        "        \n",
        "          if ittr%batch_size ==0:\n",
        "            train_loss /= batch_size\n",
        "            \n",
        "            # clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute gradientts\n",
        "            train_loss.backward()\n",
        "\n",
        "            # update parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            losses.append(train_loss.item())\n",
        "            train_loss = 0.\n",
        "  return losses"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gDFvfe4m0UI"
      },
      "source": [
        "def accuracy():\n",
        "  correct_preds = 0\n",
        "  for index,row in X_test.iterrows():\n",
        "    bow_vec = make_bow_vector(review_dict,row['stemmed_tokens'])\n",
        "    # Forward pass\n",
        "    preds = list(FFNN(bow_vec)[0])\n",
        "    if preds[0]>preds[1]:\n",
        "      out = -1\n",
        "    else :\n",
        "      out = +1\n",
        "    if out == row['label']:\n",
        "      correct_preds+=1\n",
        "  \n",
        "  return correct_preds*100/len(X_test)\n",
        "\n",
        "def plot_loss(losses):\n",
        "  if len(losses)<=100:\n",
        "    x = [i for i in range(0,len(losses))]\n",
        "    plt.plot(x,losses)\n",
        "    plt.title('Loss fnction')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('batch index')\n",
        "  else:\n",
        "    losses = losses[::len(losses)//100]\n",
        "    x = [i for i in range(0,len(losses))]\n",
        "    plt.plot(x,losses)\n",
        "    plt.title('Loss fnction')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('batch index')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4VbKMaFm6_e"
      },
      "source": [
        "VOCAB_SIZE = len(review_dict)\n",
        "\n",
        "input_size = VOCAB_SIZE\n",
        "hidden_dim = 500\n",
        "output_size = 2\n",
        "num_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "FFNN = FeedForwardNN(input_size,hidden_dim,output_size)\n",
        "FFNN.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(FFNN.parameters(), lr = 0.001)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfbbvvGtm_I7"
      },
      "source": [
        "losses = train(num_epochs,batch_size,optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxTo7WoQnWoJ"
      },
      "source": [
        "print(accuracy())\n",
        "\n",
        "plot_loss(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C5Ci7QGor3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}